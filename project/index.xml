<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Projects | Jiawen Yao</title>
    <link>https://utayao.github.io/project/</link>
      <atom:link href="https://utayao.github.io/project/index.xml" rel="self" type="application/rss+xml" />
    <description>Projects</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><lastBuildDate>Thu, 23 Nov 2023 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://utayao.github.io/images/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_512x512_fill_lanczos_center_2.png</url>
      <title>Projects</title>
      <link>https://utayao.github.io/project/</link>
    </image>
    
    <item>
      <title>AI in Oncology</title>
      <link>https://utayao.github.io/project/pancreas-project/</link>
      <pubDate>Thu, 23 Nov 2023 00:00:00 +0000</pubDate>
      <guid>https://utayao.github.io/project/pancreas-project/</guid>
      <description>&lt;h3 id=&#34;purpose&#34;&gt;Purpose:&lt;/h3&gt;
&lt;p&gt;We published a recent study to develop a deep learning-based approach using non-contrast computed tomography (CT) scans for high-accuracy detection and classification of pancreatic lesions for the early detection and treatment of pancreatic ductal adenocarcinoma (PDAC).&lt;/p&gt;
&lt;p&gt;Accurate prognostic stratification of patients with oropharyngeal squamous cell carcinoma (OPSCC) is crucial. We developed an objective and robust deep learning–based fully- automated tool called the DeepPET-OPSCC biomarker for predict- ing overall survival (OS) in OPSCC using [18F]fluorodeoxyglucose (FDG)-PET imaging.&lt;/p&gt;
&lt;h3 id=&#34;study-design&#34;&gt;Study Design:&lt;/h3&gt;
&lt;p&gt;Experimental Design: The DeepPET-OPSCC prediction model was built and tested internally on a discovery cohort (n=268) by integrating five convolutional neural network models for volumetric segmentation and ten models for OS prognostication. Two external test cohorts were enrolled—the first based on the Cancer Imaging Archive (TCIA) database (n=353) and the second being a clinical deployment cohort (n=31)—to assess the DeepPET-OPSCC performance and goodness of fit.&lt;/p&gt;
&lt;h3 id=&#34;demo-code&#34;&gt;Demo Code:&lt;/h3&gt;
&lt;p&gt;The DeepPET-OPSCC demo could be found 
&lt;a href=&#34;https://github.com/deep-med/DeepPET-OPSCC-Example&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;ref&#34;&gt;Ref&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;
&lt;a href=&#34;https://www.nature.com/articles/s41591-023-02640-w&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Large-scale pancreatic cancer detection via non-contrast CT and deep learning&lt;/a&gt;, Nature Medicine, 2023&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;
&lt;a href=&#34;https://clincancerres.aacrjournals.org/content/early/2021/06/03/1078-0432.CCR-20-4935&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Deep Learning for Fully Automated Prediction of Overall
Survival in Patients with Oropharyngeal Cancer Using
FDG-PET Imaging&lt;/a&gt;, Clinical Cancer Research, 2021, OnlineFirst.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Research Project</title>
      <link>https://utayao.github.io/project/external-project/</link>
      <pubDate>Sun, 03 May 2020 00:00:00 +0000</pubDate>
      <guid>https://utayao.github.io/project/external-project/</guid>
      <description>&lt;p&gt;Survival prediction, one very important task in prognosis, now meets many deep learning approaches. Several deep survival learning models are proposed for predicting the surivals of cancer patients from the provided multi-modal data of patients.&lt;/p&gt;
&lt;p&gt;Technological advances create a great opportunity to provide multi-view data for patients including 3D/4D radiological imaging, High resolutional pathological slides, gene expression, etc. For example in imaging data, traditional surival models mainly rely on explicitly-designed handcrafted features. This process highly relies on domain expert and human intervention which could introduce human bias and limit the use on large scale data.&lt;/p&gt;
&lt;p&gt;Deep learning have been successfully used in many medical imaging problem including detection, classification, segmentation.
Survival prediction describes how patients will survival in the future. Depend on the event, it also includes the predication of Overall Survival (OS), Disease Free Survival (DFS) or other prognostic factor prediction. One of my research work is survival prediction using various imaging modality including CT, pathology and genomics. The following show papers that I authored or co-authored in recent years.&lt;/p&gt;
&lt;h3 id=&#34;ct&#34;&gt;CT&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;
&lt;a href=&#34;https://arxiv.org/pdf/2308.00507.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Improved Prognostic Prediction of Pancreatic Cancer Using Multi-phase CT by Integrating Neural Distance and Texture-Aware Transformer&lt;/a&gt;, In MICCAI 2023.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;
&lt;a href=&#34;https://journals.lww.com/annalsofsurgery/abstract/2023/07000/deep_learning_for_fully_automated_prediction_of.33.aspx&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Deep learning for fully automated prediction of overall survival in patients undergoing resection for pancreatic cancer: a retrospective multicenter study&lt;/a&gt;, Annals of surgery 278 (1), e68-e79, 2023&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;
&lt;a href=&#34;https://lelu007.github.io/publication/1-s2.0-S1361841521001961-main.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;DeepPrognosis: Preoperative prediction of pancreatic cancer survival and surgical margin via comprehensive understanding of dynamic contrast-enhanced CT imaging and tumor-vascular contact parsing&lt;/a&gt;, Medical image analysis 73, 102150, 2021. (MICCAI-MedIA Special Issue of Best Papers in 2020)&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;pathology&#34;&gt;Pathology&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;
&lt;a href=&#34;https://arxiv.org/pdf/2009.11169.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Whole Slide Images based Cancer Survival Prediction using Attention Guided Deep Multiple Instance Learning Networks&lt;/a&gt;, Medical Image Analysis, 2020. (Most Cited Articles since 2020)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;
&lt;a href=&#34;https://link.springer.com/chapter/10.1007/978-3-030-32239-7_55&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Deep Multi-instance Learning for Survival Prediction from Whole Slide Images&lt;/a&gt;, In MICCAI 2019.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;
&lt;a href=&#34;https://link.springer.com/chapter/10.1007/978-3-030-00934-2_20&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Graph CNN for survival analysis on whole slide pathological images&lt;/a&gt;, In MICCAI 2018.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;
&lt;a href=&#34;https://openaccess.thecvf.com/content_cvpr_2017/papers/Zhu_WSISA_Making_Survival_CVPR_2017_paper.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Wsisa: Making survival prediction from whole slide histopathological images&lt;/a&gt;, In CVPR 2017.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;One of earliest work developing weakly-supervised survival model for pathology whole slides.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;
&lt;a href=&#34;https://ieeexplore.ieee.org/document/7822579&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Deep convolutional neural network for survival analysis with pathological images&lt;/a&gt;, In BIBM 2016.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The first work developing deep survival model for pathology images, known as DeepConvSurv.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;
&lt;a href=&#34;https://link.springer.com/chapter/10.1007/978-3-319-46723-8_75&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Imaging biomarker discovery for lung cancer survival prediction&lt;/a&gt;, In MICCAI 2016.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;pet&#34;&gt;PET&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;a href=&#34;https://aacrjournals.org/clincancerres/article/27/14/3948/671553/Deep-Learning-for-Fully-Automated-Prediction-of&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Deep learning for fully automated prediction of overall survival in patients with oropharyngeal cancer using FDG-PET imaging&lt;/a&gt;, Clinical Cancer Research 27 (14), 3948-3959, 2021&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;image-omics&#34;&gt;Image-Omics&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;
&lt;a href=&#34;https://link.springer.com/chapter/10.1007/978-3-319-66185-8_46&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Deep correlational learning for survival prediction from multi-modality data&lt;/a&gt;, In MICCAI 2017.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;
&lt;a href=&#34;https://ieeexplore.ieee.org/document/7822559&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Imaging-genetic data mapping for clinical outcome prediction via supervised conditional gaussian graphical model&lt;/a&gt;, In ISBI 2016.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
  </channel>
</rss>
